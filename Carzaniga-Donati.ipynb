{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Introduction to machine learning\n",
    "### Francesco Carzaniga and Sonia Donati\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the project is to find the best machine learning algorithm for a particular dataset.\n",
    "\n",
    "The algorithms that we are going to use are: Support Vector Machine (with three different kernels), K-nearest neighbour, Artificial Neural Network and finally Random Forest (implemented by us)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data 'dataset32.csv' is compiled from car accidents, classified according to their severity.\n",
    "* Number of samples: 499\n",
    "* Number of features: 13\n",
    "\n",
    "The considered features are as follows:\n",
    "\n",
    "0. '**time_to_aid**': time before receiving first aid (in minutes)\n",
    "1. '**time_from_road_check**': time from last road maintenance (in years)\n",
    "2. '**avg_speed**': average speed at impact\n",
    "3. '**road_state**': average number of injured people per vehicle\n",
    "4. '**ppl_vehicle**': average number of people per vehicle\n",
    "5. '**avg_time_in_care**': average time spent in hospital care per injured person\n",
    "6. '**num_rescue**': number of rescuers on the scene\n",
    "7. '**time_to_hospital**': time to reach the hospital (in minutes)\n",
    "8. '**age_vehicles**': average age of vehicles involved\n",
    "9. '**time_from_vehicle_check**': time from last vehicle safety check\n",
    "10. '**road_type**': road network type (local, regional, national)\n",
    "\n",
    "The goal is to predict the severity of an accident. \n",
    "\n",
    "**Remarks:** \n",
    "* '**class**': accident severity (0 = no injuries, 1 = non-fatal, 2 = fatal injuries) is not a feature\n",
    "* '**vehicle_number**': vehicle registration number is not useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we have to import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, MetaEstimatorMixin\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load the dataset using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset32.csv', delimiter = \";\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way we obtain our dataset as a numpy array. \\\n",
    "The last column contain the classes (i.e. 0, 1, 2), we call it *y*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = dataset[:,13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, it is important to notice that the three classes are well balanced, as is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33867735470941884, 0.34468937875751504, 0.3166332665330661]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print([counts[i]/np.sum(counts) for i in range(len(counts))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reshape *y* and create a copy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = y.astype(np.float).reshape((dataset.shape[0],1))\n",
    "\n",
    "y_Rf = np.copy(y) # for Random forest (see Chapter 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can select the features. In this case, we omit the last and third-last column of the dataset (see Remarks in the previous chapter). Again we also create a copy that will maintain the categorical features for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499, 12)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset[:,[0,1,2,3,4,5,6,7,8,9,10,12]]\n",
    "print(dataset.shape)\n",
    "\n",
    "dataset_Rf = np.copy(dataset) # dataset with strings for Random forest (see Chapter 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the dataset presents some strings and missing values. In what follows, we transform these strings to integers.\n",
    "We cannot however perform the imputation already, as it would leak information from the test to the train subsets we will introduce later. We have to split first and then do imputation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 6 has 4 NaN value(s)\n",
      "Feature 7 has 6 NaN value(s)\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "dataset[:,3] = le.fit_transform(dataset[:,3])  # 'road_state': average = 0, bad = 1, good = 2\n",
    "dataset[:,11] = le.fit_transform(dataset[:,11])  # 'road_type': local = 0 , national = 1, regional = 2\n",
    "\n",
    "dataset = np.asarray(dataset, dtype=np.float64)  # all values of the dataset are float now\n",
    "\n",
    "# dataset has 10 NaN values, where and how many?\n",
    "for i in range(12):\n",
    "    if any(np.isnan(dataset[:,i])):\n",
    "       print(\"Feature\", i, \"has\", sum(np.isnan(dataset[:,i])), \"NaN value(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def shuffle(dataset, y):\n",
    "    z = np.hstack((dataset, y))\n",
    "    np.random.shuffle(z)\n",
    "    return np.hsplit(z, [dataset.shape[1]])\n",
    "\n",
    "dataset, y = shuffle(dataset, y)\n",
    "\n",
    "dataset_Rf, y_Rf = shuffle(dataset_Rf, y_Rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we will implement all the methods for the project. We have a multiclass classification problem, but we want to reduce it to multiple binary decisions. In order to do that, we write two Python classes that transform the task to either a OneVsOne or a OneVsAll problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OneVsOne**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class OneVsOne(BaseEstimator, ClassifierMixin, MetaEstimatorMixin):\n",
    "    def __init__(self, model=None, n_jobs=-1, **parameters): # initialize self \n",
    "        self.model = model\n",
    "        self.n_jobs = n_jobs\n",
    "        self.parameters = parameters\n",
    "        self.classes = None\n",
    "        self.model_list = None\n",
    "\n",
    "    def get_params(self, deep=True): # get parameters\n",
    "        return {**{\"model\": self.model}, **{\"n_jobs\": self.n_jobs}, **self.parameters}\n",
    "\n",
    "    def __fit_ovo_estimator(self, X, y, class_one, class_two): # transform the models into 0 vs 1\n",
    "        class_selection = np.logical_or(y == class_one, y == class_two)\n",
    "        current_model = self.model().set_params(**self.parameters)\n",
    "        y = y[class_selection]\n",
    "        y_binarized = np.zeros_like(y)\n",
    "        y_binarized[y == class_one] = 0\n",
    "        y_binarized[y == class_two] = 1\n",
    "        X = X[class_selection]\n",
    "        current_model.fit(X, y_binarized)\n",
    "        return current_model, class_one, class_two\n",
    "\n",
    "    def fit(self, X, y): # use parallel implementation to fit estimator for each pair of classes\n",
    "        self.classes = np.unique(y)\n",
    "        models = Parallel(n_jobs=self.n_jobs)(delayed(self.__fit_ovo_estimator)\n",
    "                                              (X, y, self.classes[i], self.classes[j]) for i in range(len(self.classes))\n",
    "                                              for j in range(i + 1, len(self.classes)))\n",
    "        self.model_list = list(zip(*models))\n",
    "        return\n",
    "\n",
    "    @staticmethod\n",
    "    def __predict_ovo_estimator(X, model):\n",
    "        return model.predict(X)\n",
    "\n",
    "    @staticmethod\n",
    "    def __predict_proba_ovo_estimator(X, model): \n",
    "        # the method predict_proba or decision_function, already present in the models,\n",
    "        # outputs which model is the most confident \n",
    "        try:\n",
    "            confidence = np.max(model.predict_proba(X), axis=1)\n",
    "        except (AttributeError, NotImplementedError):\n",
    "            confidence = model.decision_function(X)\n",
    "        return confidence\n",
    "\n",
    "    def predict(self, X): \n",
    "        # predict from a certain model the best class for every label in X\n",
    "        # if there are possible ties between the models, \n",
    "        # the function takes the class with the most confidence\n",
    "        models = self.model_list[0]\n",
    "        predictions = np.stack(Parallel(n_jobs=self.n_jobs)(delayed(self.__predict_ovo_estimator)(X, models[i])\n",
    "                                                            for i in range(len(models)))).astype(dtype=np.int32).T\n",
    "        confidences = np.stack(Parallel(n_jobs=self.n_jobs)(delayed(self.__predict_proba_ovo_estimator)(X, models[i])\n",
    "                                                            for i in range(len(models)))).T\n",
    "        votes = np.zeros((X.shape[0], self.classes.size))\n",
    "        total_confidences = np.zeros_like(votes)\n",
    "        for model in range(len(models)):\n",
    "            class_one_m = self.model_list[1][model]\n",
    "            class_two_m = self.model_list[2][model]\n",
    "            votes[predictions[:, model] == 0, np.argwhere(self.classes == class_one_m)[0]] += 1\n",
    "            votes[predictions[:, model] == 1, np.argwhere(self.classes == class_two_m)[0]] += 1\n",
    "            total_confidences[predictions[:, model] == 0, np.argwhere(self.classes == class_one_m)[0]] += \\\n",
    "                confidences[predictions[:, model] == 0, model]\n",
    "            total_confidences[predictions[:, model] == 1, np.argwhere(self.classes == class_two_m)[0]] += \\\n",
    "                confidences[predictions[:, model] == 1, model]\n",
    "        # trasform confidences between [-1/3, 1/3] to avoid overriding the votes, clever trick taken from sklearn\n",
    "        transformed_confidences = (total_confidences /\n",
    "                                   (3 * (np.abs(total_confidences) + 1))) \n",
    "        winners = self.classes[np.argmax(votes+transformed_confidences, axis=1)]\n",
    "        return winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OneVsAll**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class OneVsAll(object):\n",
    "    def __init__(self, model=None, n_jobs=-1, **parameters): # initialize self\n",
    "        self.model = model\n",
    "        self.model_list = []\n",
    "        self.n_jobs = n_jobs\n",
    "        self.classes = None\n",
    "        self.parameters = parameters\n",
    "\n",
    "    def get_params(self, deep=True): # get parameters\n",
    "        return {**{\"model\": self.model}, **{\"n_jobs\": self.n_jobs}, **self.parameters}\n",
    " \n",
    "    def set_params(self, **parameters): # set parameters\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def __fit_ova_estimator(self, X, y, class_one): # trasform all the models into 1 vs 0 (class_one is 1, the rest 0)\n",
    "        current_model = self.model().set_params(**self.parameters)\n",
    "        y_binarized = np.zeros_like(y)\n",
    "        y_binarized[y == class_one] = 1\n",
    "        y_binarized[y != class_one] = 0\n",
    "        current_model.fit(X, y_binarized)\n",
    "        return current_model, class_one\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        models = Parallel(n_jobs=self.n_jobs)(delayed(self.__fit_ova_estimator)\n",
    "                                              (X, y, self.classes[i]) for i in range(len(self.classes)))\n",
    "        self.model_list = list(zip(*models))\n",
    "        return\n",
    "    \n",
    "    @staticmethod\n",
    "    def __predict_ova_estimator(X, model):\n",
    "        return model.predict(X)\n",
    "\n",
    "    @staticmethod\n",
    "    def __predict_proba_ova_estimator(X, model):\n",
    "        try:\n",
    "            confidence = np.max(model.predict_proba(X), axis=1)\n",
    "        except (AttributeError, NotImplementedError):\n",
    "            confidence = model.decision_function(X)\n",
    "        return confidence\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # predict from a certain model the best class for every label in X\n",
    "        # if there are possible misunderstanding between the models, \n",
    "        # the function take the class given by the most confident model\n",
    "        models = self.model_list[0]\n",
    "        predictions = np.stack(Parallel(n_jobs=self.n_jobs)(delayed(self.__predict_ova_estimator)(X, models[i])\n",
    "                                                            for i in range(len(models)))).astype(dtype=np.int32)\n",
    "        confidences = np.stack(Parallel(n_jobs=self.n_jobs)(delayed(self.__predict_proba_ova_estimator)(X, models[i])\n",
    "                                                            for i in range(len(models))))\n",
    "        \n",
    "        val = []\n",
    "        for k in range(X.shape[0]):\n",
    "            index = np.argwhere(predictions[:,k] == 1)\n",
    "            if index.size == 1: # if there is a unique 1 in the column k\n",
    "                val.append(self.classes[index])\n",
    "            elif index.size == 0: # if there are none\n",
    "                conf = confidences[:,k]\n",
    "                val.append(self.classes[np.argmax(conf)])\n",
    "            else:\n",
    "                conf = np.multiply((predictions[:, k] + confidences[:, k]), (predictions[:, k]))  # add the confidence only to the values with 1\n",
    "                val.append(self.classes[np.argmax(conf)])\n",
    "        val_array = np.asarray(val)\n",
    "        return val_array\n",
    "\n",
    "    def score(self, X, y): # this function returns the accuracy of the prediction given X and y\n",
    "        label_predict = self.predict(X)\n",
    "        loss = np.mean(y.ravel() == label_predict)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wanted to implement the solutions in two different ways, in fact the first one vectorizes over the samples while the second one over the models. The tie breaking decisions are taken in the standard way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last thing to implement is the Random forest algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we build a tree class that serves as a basic data structure for our model. On top of it we build a decision tree using the C4.5 algorithm, and finally we construct the random forest from multiple decision trees.\n",
    "\n",
    "**Rmk:** \n",
    "* C4.5 algorithm is different from the one used in sklearn, which is CART\n",
    "* Advantage: C4.5 algorithm supports both numerical and categorical values, while CART does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    def __init__(self, parent=None, children=None, feature=None, threshold=None, direction=None, excluded_samples=None,\n",
    "                 is_leaf=False, decision=None, confidence=None):\n",
    "        if children is None:\n",
    "            children = []\n",
    "        self.parent = parent\n",
    "        self.children = children\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.direction = direction\n",
    "        self.excluded_samples = excluded_samples\n",
    "        self.is_leaf = is_leaf\n",
    "        self.decision = decision\n",
    "        self.confidence = confidence\n",
    "        self.depth = self.compute_depth()\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    def compute_depth(self): # compute the depth of the tree\n",
    "        depth = 0\n",
    "        node = self\n",
    "        while node.parent is not None:\n",
    "            node = node.parent\n",
    "            depth += 1\n",
    "        return depth\n",
    "\n",
    "    def add_child(self, child): # append element to children list\n",
    "        self.children.append(child)\n",
    "\n",
    "    def get_parent(self):\n",
    "        return self.parent\n",
    "\n",
    "    def get_children(self):\n",
    "        return self.children\n",
    "\n",
    "    def get_feature(self):\n",
    "        return self.feature\n",
    "\n",
    "    def get_threshold(self):\n",
    "        return self.threshold\n",
    "\n",
    "    def get_all_features(self): # get the features of this node and all the parents\n",
    "        node = self\n",
    "        features_list = []\n",
    "        while node is not None:\n",
    "            features_list.append(int(node.get_feature()))\n",
    "            node = node.parent\n",
    "        return np.asarray(features_list)\n",
    "\n",
    "    def get_direction(self):\n",
    "        return self.direction\n",
    "\n",
    "    def set_parent(self, parent):\n",
    "        self.parent = parent\n",
    "\n",
    "    def set_feature(self, feature):\n",
    "        self.feature = feature\n",
    "\n",
    "    def set_threshold(self, threshold):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def set_direction(self, direction):\n",
    "        self.direction = direction\n",
    "\n",
    "    def __max_depth(self, tree): # depth of the tree starting from this node\n",
    "        if tree.is_leaf:\n",
    "            return 0\n",
    "        elif len(tree.children) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            depth = []\n",
    "            for child in tree.children:\n",
    "                depth.append(self.__max_depth(child))\n",
    "            return np.amax(depth)+1.\n",
    "\n",
    "    def get_max_depth(self):\n",
    "        return self.__max_depth(self)\n",
    "\n",
    "    def get_depth(self):\n",
    "        return self.depth\n",
    "\n",
    "    def set_excluded_samples(self, excluded_samples):\n",
    "        self.excluded_samples = excluded_samples\n",
    "        return\n",
    "\n",
    "    def get_all_excluded_samples(self): # get the samples excluded by this node and all the parents\n",
    "        node = self\n",
    "        samples_list = np.asarray([])\n",
    "        while node is not None:\n",
    "            samples_list = np.concatenate([samples_list, node.get_excluded_samples().ravel()])\n",
    "            node = node.parent\n",
    "        return np.asarray(samples_list)\n",
    "\n",
    "    def get_is_leaf(self):\n",
    "        return self.is_leaf\n",
    "\n",
    "    def set_is_leaf(self, is_leaf):\n",
    "        self.is_leaf = is_leaf\n",
    "\n",
    "    def get_decision(self):\n",
    "        return self.decision\n",
    "\n",
    "    def set_decision(self, decision):\n",
    "        self.decision = decision\n",
    "\n",
    "    def get_excluded_samples(self):\n",
    "        return np.asarray(self.excluded_samples)\n",
    "\n",
    "    def get_confidence(self):\n",
    "        return self.confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DecisionTree(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, max_depth=None, max_features=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.tree = None\n",
    "        self._queue = []\n",
    "        self.classes = None\n",
    "\n",
    "    @staticmethod\n",
    "    def __entropy(labels): # compute entropy\n",
    "        if labels.size == 0:\n",
    "            return 0\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        return np.sum([-counts[i]/np.sum(counts)*np.log2(counts[i]/np.sum(counts)) for i in range(len(unique))])\n",
    "\n",
    "    def __gain(self, y, subsets):  \n",
    "    # normalized information gain of a feature, so that we can choose the most efficient one to use\n",
    "    # i.e. (initial entropy of all labels -  entropy of labels with some chosen feature)\n",
    "        entropy_node = self.__entropy(y)\n",
    "        total_length = np.sum([subset.size for subset in subsets], dtype=np.float64)\n",
    "        weights = [subset.size/total_length for subset in subsets]\n",
    "        entropy_child = np.sum([weights[i]*self.__entropy(y[subsets[i]]) for i in range(len(subsets))])\n",
    "        return entropy_node-entropy_child\n",
    "\n",
    "    def __split(self, X, y, node, excluded_samples=None, direction=None):\n",
    "    # Choose remaining features and samples to be tested\n",
    "        dataset_size, label_size = X.shape\n",
    "        if excluded_samples is None:\n",
    "            excluded_samples = []\n",
    "        if node is not None:\n",
    "            excluded_features = node.get_all_features()\n",
    "            features = np.delete(np.arange(label_size), excluded_features)\n",
    "            all_excluded_samples = node.get_all_excluded_samples()\n",
    "            all_excluded_samples = np.concatenate([all_excluded_samples, excluded_samples]).astype(dtype=np.int32)\n",
    "            samples = np.delete(np.arange(dataset_size), all_excluded_samples)\n",
    "        else:\n",
    "            features = np.arange(label_size)\n",
    "            samples = np.arange(dataset_size)\n",
    "        y_orig = np.copy(y)\n",
    "        X = X[samples]\n",
    "        y = y[samples]\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        confidence = np.zeros(2)\n",
    "        # Base case 1, labels are all the same so create leaf where decision is label\n",
    "        if classes.size == 1:\n",
    "            confidence[np.argwhere(self.classes == classes[0])] = 1.\n",
    "            leaf = Tree(parent=node, decision=classes[0], direction=direction, is_leaf=True, confidence=confidence)\n",
    "            node.add_child(leaf)\n",
    "            return 1\n",
    "        # Base case 2, no labels associated to this class so decide with the most frequent label of parent\n",
    "        elif classes.size == 0:\n",
    "            unique, counts = np.unique(y_orig[samples], return_counts=True)\n",
    "            total_labels = np.sum(counts)\n",
    "            for u in range(unique.size):\n",
    "                confidence[np.argwhere(self.classes == unique[u])] = counts[u]/total_labels\n",
    "            all_excluded_samples = node.get_all_excluded_samples().astype(dtype=np.int32)\n",
    "            samples = np.delete(np.arange(dataset_size), all_excluded_samples)\n",
    "            leaf = Tree(parent=node, decision=int(np.median(y_orig[samples]).round()), direction=direction,\n",
    "                        is_leaf=True, confidence=confidence)\n",
    "            node.add_child(leaf)\n",
    "            return 2\n",
    "        # Max depth parameter must be respected\n",
    "        if self.max_depth is not None and node is not None and node.get_max_depth() == self.max_depth - 1:\n",
    "            unique, counts = np.unique(y, return_counts=True)\n",
    "            total_labels = np.sum(counts)\n",
    "            for u in range(unique.size):\n",
    "                confidence[np.argwhere(self.classes == unique[u])] = counts[u]/total_labels\n",
    "            leaf = Tree(parent=node, decision=int(np.median(y).round()), direction=direction, is_leaf=True,\n",
    "                        confidence=confidence)\n",
    "            node.add_child(leaf)\n",
    "            return 4\n",
    "        # Max_features must be respected\n",
    "        max_features = self.max_features\n",
    "        if max_features is not None and features.size > max_features:\n",
    "            random_features = np.random.choice(features, max_features, replace=False)\n",
    "        else:\n",
    "            random_features = features\n",
    "            \n",
    "        # Try all the chosen features. Obtain feature with best gain and its threshold.\n",
    "        max_gain = 0.\n",
    "        max_feature = -1\n",
    "        best_threshold = None\n",
    "        for feature in random_features:\n",
    "            feature_vector = X[:, feature]\n",
    "            try:\n",
    "                feature_vector = np.array(feature_vector, dtype=np.float64) # if numerical convert to float64\n",
    "            except ValueError:\n",
    "                feature_vector = np.array(feature_vector, dtype=object) # if categorical convert to object\n",
    "            unique, counts = np.unique(feature_vector, return_counts=True)\n",
    "            if feature_vector.dtype == 'object': # categorical case\n",
    "                subsets = [np.argwhere(feature_vector == u) for u in unique]\n",
    "                gain = self.__gain(y, subsets)\n",
    "                threshold = None\n",
    "            elif feature_vector.dtype == 'float64': # numerical case\n",
    "                threshold_gains = []\n",
    "                for u in unique:\n",
    "                    below = np.argwhere(feature_vector <= u)\n",
    "                    above = np.argwhere(feature_vector > u)\n",
    "                    threshold_gains.append(self.__gain(y, [below, above]))\n",
    "                gain = np.nanmax(threshold_gains) # take maximal gain\n",
    "                threshold = unique[np.nanargmax(threshold_gains)]\n",
    "            if gain > max_gain:\n",
    "                max_gain = gain\n",
    "                max_feature = feature\n",
    "                best_threshold = threshold\n",
    "        # Base case 3. Can no longer get better, make parent a leaf.\n",
    "        if max_gain == 0.:\n",
    "            unique, counts = np.unique(y_orig[samples], return_counts=True)\n",
    "            total_labels = np.sum(counts)\n",
    "            for u in range(unique.size):\n",
    "                confidence[np.argwhere(self.classes == unique[u])] = counts[u] / total_labels\n",
    "            all_excluded_samples = node.get_all_excluded_samples().astype(dtype=np.int32)\n",
    "            samples = np.delete(np.arange(dataset_size), all_excluded_samples)\n",
    "            new_node = Tree(parent=node.parent, decision=int(np.median(y_orig[samples]).round()),\n",
    "                            direction=node.get_direction(), is_leaf=True, confidence=confidence)\n",
    "            substitute = node.parent.children.index(node)\n",
    "            node.parent.children[substitute] = new_node\n",
    "            return 3\n",
    "        # Create new node with best feature. If there is entropy gain, create new node (node not leaf!).\n",
    "        new_node = Tree(parent=node, direction=direction, feature=max_feature, threshold=best_threshold,\n",
    "                        excluded_samples=excluded_samples)\n",
    "        if node is not None:\n",
    "            node.add_child(new_node)\n",
    "        return new_node\n",
    "\n",
    "    def __create_nodes_numerical(self, X, y, feature_vector, node_thresh, node):\n",
    "        less = np.argwhere(feature_vector <= node_thresh).ravel()\n",
    "        great = np.argwhere(feature_vector > node_thresh).ravel()\n",
    "        case = self.__split(X, y, node, great, 'l')\n",
    "        if isinstance(case, Tree):\n",
    "            self._queue.append(case)\n",
    "        elif case == 3:\n",
    "            return\n",
    "        case = self.__split(X, y, node, less, 'g')\n",
    "        if isinstance(case, Tree):\n",
    "            self._queue.append(case)\n",
    "        elif case == 3:\n",
    "            return\n",
    "\n",
    "    def __create_nodes_categorical(self, X, y, feature_vector, unique, node):\n",
    "        for u in unique:\n",
    "            excluded_samples = np.argwhere(feature_vector != u).ravel()\n",
    "            case = self.__split(X, y, node, excluded_samples, u)\n",
    "            if isinstance(case, Tree):\n",
    "                self._queue.append(case)\n",
    "            elif case == 3:\n",
    "                return\n",
    "\n",
    "    def fit(self, X, y): # build tree breadth-wise\n",
    "        if self.max_features is None:\n",
    "            self.max_features = X.shape[1]\n",
    "        self.classes = np.unique(y)\n",
    "        self.tree = self.__split(X, y, self.tree)\n",
    "        self._queue.append(self.tree)\n",
    "        while len(self._queue) > 0:\n",
    "            node = self._queue.pop()\n",
    "            node_feat = node.get_feature()\n",
    "            node_thresh = node.get_threshold()\n",
    "            feature_vector = X[:, node_feat]\n",
    "            unique, counts = np.unique(feature_vector, return_counts=True)\n",
    "            if node_thresh is None:\n",
    "                self.__create_nodes_categorical(X, y, feature_vector, unique, node)\n",
    "            else:\n",
    "                self.__create_nodes_numerical(X, y, feature_vector, node_thresh, node)\n",
    "        return\n",
    "\n",
    "    def predict(self, X): # traverse the tree and take leaf decision\n",
    "        prediction = []\n",
    "        for sample in X:\n",
    "            node = self.tree\n",
    "            while not node.is_leaf:\n",
    "                feature = node.get_feature()\n",
    "                threshold = node.get_threshold()\n",
    "                if threshold is None:\n",
    "                    value = sample[feature]\n",
    "                    children_direction = [child.direction for child in node.children]\n",
    "                    direction = children_direction.index(value)\n",
    "                    node = node.children[direction]\n",
    "                else:\n",
    "                    if sample[feature] - threshold < 0:\n",
    "                        direction = 0\n",
    "                    else:\n",
    "                        direction = 1\n",
    "                    node = node.children[direction]\n",
    "            prediction.append(node.get_decision())\n",
    "        return np.asarray(prediction)\n",
    "\n",
    "    def predict_proba(self, X): # for the confidence (used in OneVsOne, OneVsAll)\n",
    "        proba = []\n",
    "        for sample in X:\n",
    "            node = self.tree\n",
    "            while not node.is_leaf:\n",
    "                feature = node.get_feature()\n",
    "                threshold = node.get_threshold()\n",
    "                if threshold is None:\n",
    "                    value = sample[feature]\n",
    "                    children_direction = [child.direction for child in node.children]\n",
    "                    direction = children_direction.index(value)\n",
    "                    node = node.children[direction]\n",
    "                else:\n",
    "                    if sample[feature] - threshold < 0:\n",
    "                        direction = 0\n",
    "                    else:\n",
    "                        direction = 1\n",
    "                    node = node.children[direction]\n",
    "            proba.append(node.get_confidence())\n",
    "        return np.asarray(proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RandomForest(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, max_depth=None, max_features=None, n_estimators=10, bootstrap=1., n_jobs=-1):\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.n_estimators = n_estimators\n",
    "        self.n_jobs = n_jobs\n",
    "        self.bootstrap = bootstrap\n",
    "        self._estimators = []\n",
    "\n",
    "    def __make_estimators(self): # build trees in a parallel way\n",
    "        estimators = Parallel(n_jobs=self.n_jobs)\\\n",
    "            (delayed(DecisionTree)(max_depth=self.max_depth, max_features=self.max_features)\n",
    "             for i in range(self.n_estimators))\n",
    "        return estimators\n",
    "\n",
    "    @staticmethod\n",
    "    def __parallel_build_trees(tree, X, y, bootstrap): # build single tree\n",
    "        if bootstrap:\n",
    "            samples = np.random.choice(np.arange(X.shape[0]), int(bootstrap*X.shape[0]))\n",
    "            X = X[samples]\n",
    "            y = y[samples]\n",
    "        tree.fit(X, y)\n",
    "        return tree\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        estimators = self.__make_estimators()\n",
    "        result = Parallel(n_jobs=self.n_jobs)\\\n",
    "            (delayed(self.__parallel_build_trees)(tree, X, y, self.bootstrap) for tree in estimators)\n",
    "        self._estimators = result\n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        results = Parallel(n_jobs=self.n_jobs)(delayed(element.predict)(X) for element in self._estimators)\n",
    "        return np.median(np.stack(results), axis=0).round()\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        results = Parallel(n_jobs=self.n_jobs)(delayed(element.predict_proba)(X) for element in self._estimators)\n",
    "        return np.mean(np.stack(results, axis=2), axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validation and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we do 5-fold cross-validation for all the models. First with OneVsOne, then with OneVsAll.\n",
    "\n",
    "**Rmk:** Cross-validation is a more robust method than the classic splitting into train and test sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid clutter, we first initialize the imputer that will be used for all the computations (except RandomForest). The reason is explained in Section 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_imputer = SimpleImputer(missing_values = np.nan, strategy=\"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM (Default: Kernel \"rbf\")**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.446348</td>\n",
       "      <td>4.040210</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.887950</td>\n",
       "      <td>3.642261</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.874985</td>\n",
       "      <td>3.655622</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.863017</td>\n",
       "      <td>4.050170</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.970728</td>\n",
       "      <td>3.784879</td>\n",
       "      <td>0.808081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  2.446348    4.040210    0.850000\n",
       "1  1.887950    3.642261    0.800000\n",
       "2  1.874985    3.655622    0.800000\n",
       "3  1.863017    4.050170    0.880000\n",
       "4  1.970728    3.784879    0.808081"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mean of the test_score with OneVsOne: 0.8276161616161616\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.955773</td>\n",
       "      <td>3.920513</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.957763</td>\n",
       "      <td>4.033213</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.879976</td>\n",
       "      <td>3.878627</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.515272</td>\n",
       "      <td>4.628646</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.347476</td>\n",
       "      <td>4.476092</td>\n",
       "      <td>0.808081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  1.955773    3.920513    0.860000\n",
       "1  1.957763    4.033213    0.820000\n",
       "2  1.879976    3.878627    0.800000\n",
       "3  2.515272    4.628646    0.880000\n",
       "4  2.347476    4.476092    0.808081"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mean of the test_score with OneVsAll: 0.8336161616161617\n"
     ]
    }
   ],
   "source": [
    "model_SVM = svm.SVC\n",
    "\n",
    "# do imputation and trasform the multiclass problem to OnevsOne\n",
    "onevone_transform = OneVsOne(model_SVM, gamma = \"auto\")\n",
    "estimator_ovo = Pipeline([(\"Imputer\", median_imputer),(\"Transformer\", onevone_transform)])\n",
    "\n",
    "# do cross-validation\n",
    "val_ovo = cross_validate(estimator_ovo, dataset, y.ravel(), cv=5)\n",
    "\n",
    "display(pd.DataFrame(val_ovo))\n",
    "mean_val_ovo = val_ovo[\"test_score\"].mean()\n",
    "print(\"This is the mean of the test_score with OneVsOne:\", mean_val_ovo)\n",
    "\n",
    "# Now the same with OnevsAll\n",
    "\n",
    "onevall_transform = OneVsAll(model_SVM, gamma = \"auto\")\n",
    "estimator_ova = Pipeline([(\"Imputer\", median_imputer),(\"Transformer\", onevall_transform)])\n",
    "\n",
    "val_ova = cross_validate(estimator_ova, dataset, y.ravel(), cv=5)\n",
    "\n",
    "display(pd.DataFrame(val_ova))\n",
    "mean_val_ova = val_ova[\"test_score\"].mean()\n",
    "print(\"This is the mean of the test_score with OneVsAll:\", mean_val_ova)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rmk:** \n",
    "* This result with gamma = \"auto\" is much better than with gamma = \"scale\" \n",
    "* In the version of sklearn 0.22 the default parameter gamma changes from \"auto\" to \"scale\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polynomially kernelized SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.129307</td>\n",
       "      <td>3.592395</td>\n",
       "      <td>0.84000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.870994</td>\n",
       "      <td>4.113002</td>\n",
       "      <td>0.71000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.944801</td>\n",
       "      <td>4.371306</td>\n",
       "      <td>0.69000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.342738</td>\n",
       "      <td>3.789866</td>\n",
       "      <td>0.81000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.924849</td>\n",
       "      <td>3.814113</td>\n",
       "      <td>0.69697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  2.129307    3.592395     0.84000\n",
       "1  1.870994    4.113002     0.71000\n",
       "2  1.944801    4.371306     0.69000\n",
       "3  2.342738    3.789866     0.81000\n",
       "4  1.924849    3.814113     0.69697"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mean of the test_score with OneVsOne: 0.7493939393939394\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.891940</td>\n",
       "      <td>3.892627</td>\n",
       "      <td>0.83000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.902872</td>\n",
       "      <td>3.891593</td>\n",
       "      <td>0.86000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.045531</td>\n",
       "      <td>3.808815</td>\n",
       "      <td>0.81000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.968734</td>\n",
       "      <td>3.815796</td>\n",
       "      <td>0.87000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.974719</td>\n",
       "      <td>3.901600</td>\n",
       "      <td>0.79798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  1.891940    3.892627     0.83000\n",
       "1  1.902872    3.891593     0.86000\n",
       "2  2.045531    3.808815     0.81000\n",
       "3  1.968734    3.815796     0.87000\n",
       "4  1.974719    3.901600     0.79798"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mean of the test_score with OneVsAll: 0.8335959595959597\n"
     ]
    }
   ],
   "source": [
    "model_poly = svm.SVC\n",
    "\n",
    "onevone_transform = OneVsOne(model_poly, kernel = 'poly')\n",
    "estimator_ovo = Pipeline([(\"Imputer\", median_imputer),(\"Transformer\", onevone_transform)])\n",
    "\n",
    "val_ovo = cross_validate(estimator_ovo, dataset, y.ravel(), cv=5)\n",
    "\n",
    "display(pd.DataFrame(val_ovo))\n",
    "mean_val_ovo = val_ovo[\"test_score\"].mean()\n",
    "print(\"This is the mean of the test_score with OneVsOne:\", mean_val_ovo)\n",
    "\n",
    "# Now the same with OnevsAll\n",
    "\n",
    "onevall_transform = OneVsAll(model_poly, kernel = 'poly')\n",
    "estimator_ova = Pipeline([(\"Imputer\", median_imputer),(\"Transformer\", onevall_transform)])\n",
    "\n",
    "val_ova = cross_validate(estimator_ova, dataset, y.ravel(), cv=5)\n",
    "\n",
    "display(pd.DataFrame(val_ova))\n",
    "mean_val_ova = val_ova[\"test_score\"].mean()\n",
    "print(\"This is the mean of the test_score with OneVsAll:\", mean_val_ova)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear kernelized SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.105370</td>\n",
       "      <td>3.847524</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.126311</td>\n",
       "      <td>4.092057</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.919864</td>\n",
       "      <td>3.789636</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.924852</td>\n",
       "      <td>3.964400</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.797193</td>\n",
       "      <td>3.688656</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  2.105370    3.847524    0.880000\n",
       "1  2.126311    4.092057    0.870000\n",
       "2  1.919864    3.789636    0.860000\n",
       "3  1.924852    3.964400    0.940000\n",
       "4  1.797193    3.688656    0.818182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mean of the test_score with OneVsOne: 0.8736363636363637\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.962791</td>\n",
       "      <td>3.911503</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.990685</td>\n",
       "      <td>3.742982</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.031565</td>\n",
       "      <td>3.722048</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.007625</td>\n",
       "      <td>3.857684</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.027575</td>\n",
       "      <td>3.788869</td>\n",
       "      <td>0.838384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  1.962791    3.911503    0.900000\n",
       "1  1.990685    3.742982    0.870000\n",
       "2  2.031565    3.722048    0.860000\n",
       "3  2.007625    3.857684    0.920000\n",
       "4  2.027575    3.788869    0.838384"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mean of the test_score with OneVsAll: 0.8776767676767676\n"
     ]
    }
   ],
   "source": [
    "model_linear = svm.SVC\n",
    "\n",
    "onevone_transform = OneVsOne(model_linear, kernel = \"linear\")\n",
    "estimator = Pipeline([(\"imputer\", median_imputer),(\"Transformer\", onevone_transform)])\n",
    "\n",
    "val_ovo = cross_validate(estimator, dataset, y.ravel(), cv=5)\n",
    "\n",
    "display(pd.DataFrame(val_ovo))\n",
    "mean_val_ovo = val_ovo[\"test_score\"].mean()\n",
    "print(\"This is the mean of the test_score with OneVsOne:\", mean_val_ovo)\n",
    "\n",
    "# Now the same with OneVsAll\n",
    "\n",
    "onevall_transform = OneVsAll(model_linear, kernel = \"linear\")\n",
    "estimator_ova = Pipeline([(\"imputer\", median_imputer),(\"Transformer\", onevall_transform)])\n",
    "\n",
    "val_ova = cross_validate(estimator_ova, dataset, y.ravel(), cv=5)\n",
    "\n",
    "display(pd.DataFrame(val_ova))\n",
    "mean_val_ova = val_ova[\"test_score\"].mean()\n",
    "print(\"This is the mean of the test_score with OneVsAll:\", mean_val_ova)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-nearest neighbour algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.117334</td>\n",
       "      <td>3.882620</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.869998</td>\n",
       "      <td>4.367321</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.932159</td>\n",
       "      <td>4.438134</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.014611</td>\n",
       "      <td>4.020250</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.927847</td>\n",
       "      <td>3.934477</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  2.117334    3.882620    0.850000\n",
       "1  1.869998    4.367321    0.760000\n",
       "2  2.932159    4.438134    0.810000\n",
       "3  2.014611    4.020250    0.830000\n",
       "4  1.927847    3.934477    0.777778"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mean of the test_score with OneVsOne: 0.8055555555555556\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.106365</td>\n",
       "      <td>3.995318</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.878975</td>\n",
       "      <td>3.930489</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.138284</td>\n",
       "      <td>4.407213</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.073456</td>\n",
       "      <td>3.962404</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.012618</td>\n",
       "      <td>4.005848</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  2.106365    3.995318    0.790000\n",
       "1  1.878975    3.930489    0.730000\n",
       "2  2.138284    4.407213    0.790000\n",
       "3  2.073456    3.962404    0.810000\n",
       "4  2.012618    4.005848    0.767677"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mean of the test_score with OneVsAll: 0.7775353535353535\n"
     ]
    }
   ],
   "source": [
    "model_K = KNeighborsClassifier\n",
    "\n",
    "onevone_transform = OneVsOne(model_K,n_neighbors=5)\n",
    "estimator_ovo = Pipeline([(\"Imputer\", median_imputer),(\"Transformer\", onevone_transform)])\n",
    "\n",
    "val_ovo = cross_validate(estimator_ovo, dataset, y.ravel(), cv=5)\n",
    "\n",
    "display(pd.DataFrame(val_ovo))\n",
    "mean_val_ovo = val_ovo[\"test_score\"].mean()\n",
    "print(\"This is the mean of the test_score with OneVsOne:\", mean_val_ovo)\n",
    "\n",
    "# Now the same with OneVsAll\n",
    "\n",
    "onevall_transform = OneVsAll(model_K,n_neighbors=5)\n",
    "estimator_ova = Pipeline([(\"Imputer\", median_imputer),(\"Transformer\", onevall_transform)])\n",
    "\n",
    "val_ova = cross_validate(estimator_ova, dataset, y.ravel(), cv=5)\n",
    "\n",
    "display(pd.DataFrame(val_ova))\n",
    "mean_val_ova = val_ova[\"test_score\"].mean()\n",
    "print(\"This is the mean of the test_score with OneVsAll:\", mean_val_ova)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Artificial neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.506298</td>\n",
       "      <td>4.104029</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.125316</td>\n",
       "      <td>3.473711</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.222054</td>\n",
       "      <td>3.743991</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.121327</td>\n",
       "      <td>3.740001</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.111387</td>\n",
       "      <td>3.847677</td>\n",
       "      <td>0.828283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  2.506298    4.104029    0.860000\n",
       "1  2.125316    3.473711    0.880000\n",
       "2  2.222054    3.743991    0.810000\n",
       "3  2.121327    3.740001    0.950000\n",
       "4  2.111387    3.847677    0.828283"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mean of the test_score with OneVsOne: 0.8656565656565658\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.406600</td>\n",
       "      <td>3.696083</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.261952</td>\n",
       "      <td>3.697110</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.439478</td>\n",
       "      <td>3.746982</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.237015</td>\n",
       "      <td>3.906554</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.339747</td>\n",
       "      <td>3.744982</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  2.406600    3.696083    0.830000\n",
       "1  2.261952    3.697110    0.880000\n",
       "2  2.439478    3.746982    0.770000\n",
       "3  2.237015    3.906554    0.890000\n",
       "4  2.339747    3.744982    0.757576"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mean of the test_score with OneVsAll: 0.8255151515151515\n"
     ]
    }
   ],
   "source": [
    "model_ANN = MLPClassifier\n",
    "\n",
    "onevone_transform = OneVsOne(model_ANN)\n",
    "estimator = Pipeline([(\"Imputer\", median_imputer),(\"Transformer\", onevone_transform)])\n",
    "\n",
    "val_ovo = cross_validate(estimator, dataset, y.ravel(), cv=5)\n",
    "\n",
    "display(pd.DataFrame(val_ovo))\n",
    "mean_val_ovo = val_ovo[\"test_score\"].mean()\n",
    "print(\"This is the mean of the test_score with OneVsOne:\", mean_val_ovo)\n",
    "\n",
    "# Now the same with OneVsAll\n",
    "\n",
    "onevall_transform = OneVsAll(model_ANN)\n",
    "estimator_ova = Pipeline([(\"imputer\", median_imputer),(\"Transformer\", onevall_transform)])\n",
    "\n",
    "val_ova = cross_validate(estimator_ova, dataset, y.ravel(), cv=5)\n",
    "\n",
    "display(pd.DataFrame(val_ova))\n",
    "mean_val_ova = val_ova[\"test_score\"].mean()\n",
    "print(\"This is the mean of the test_score with OneVsAll:\", mean_val_ova)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "\n",
    "We use first the dataset with categorical values, then with numerical values. The algorithm is very similar in both cases, but it is still interesting to observe.\n",
    "\n",
    "NB: in the former case we use the imputation strategy \"most_frequent\", since it is impossible to compute the mean with categorical values inside the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical Case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.166067</td>\n",
       "      <td>4.089506</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.468426</td>\n",
       "      <td>4.298285</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.655653</td>\n",
       "      <td>4.052078</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.578756</td>\n",
       "      <td>3.953024</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.994878</td>\n",
       "      <td>4.116960</td>\n",
       "      <td>0.858586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_score\n",
       "0  24.166067    4.089506    0.900000\n",
       "1  25.468426    4.298285    0.850000\n",
       "2  24.655653    4.052078    0.890000\n",
       "3  24.578756    3.953024    0.840000\n",
       "4  23.994878    4.116960    0.858586"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mean of the test_score with OneVsOne: 0.8677171717171717\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.123852</td>\n",
       "      <td>4.769299</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.145694</td>\n",
       "      <td>5.037460</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.054918</td>\n",
       "      <td>4.558225</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.295504</td>\n",
       "      <td>4.599126</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.844697</td>\n",
       "      <td>4.989157</td>\n",
       "      <td>0.767677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_score\n",
       "0  41.123852    4.769299    0.850000\n",
       "1  55.145694    5.037460    0.910000\n",
       "2  42.054918    4.558225    0.820000\n",
       "3  40.295504    4.599126    0.830000\n",
       "4  43.844697    4.989157    0.767677"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mean of the test_score with OneVsAll: 0.8355353535353535\n"
     ]
    }
   ],
   "source": [
    "model_Rf = RandomForest\n",
    "categorical_imputer = SimpleImputer(missing_values = np.nan, strategy = \"most_frequent\")\n",
    "\n",
    "onevone_transform = OneVsOne(model_Rf)\n",
    "estimator_ovo = Pipeline([(\"Imputer\", categorical_imputer),(\"Transformer\", onevone_transform)])\n",
    "\n",
    "val_ovo = cross_validate(estimator_ovo, dataset_Rf, y_Rf.astype(np.float).ravel(), cv=5)\n",
    "\n",
    "display(pd.DataFrame(val_ovo))\n",
    "mean_val_ovo = val_ovo[\"test_score\"].mean()\n",
    "print(\"This is the mean of the test_score with OneVsOne:\", mean_val_ovo)\n",
    "\n",
    "# Now the same with OneVsAll\n",
    "\n",
    "onevall_transform = OneVsAll(model_Rf)\n",
    "estimator_ova = Pipeline([(\"Imputer\", categorical_imputer),(\"Transformer\", onevall_transform)])\n",
    "\n",
    "val_ova = cross_validate(estimator_ova, dataset_Rf, y_Rf.astype(np.float).ravel(), cv=5)\n",
    "\n",
    "display(pd.DataFrame(val_ova))\n",
    "mean_val_ova = val_ova[\"test_score\"].mean()\n",
    "print(\"This is the mean of the test_score with OneVsAll:\", mean_val_ova)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.369689</td>\n",
       "      <td>4.388958</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.738514</td>\n",
       "      <td>3.828265</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.612033</td>\n",
       "      <td>4.037036</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.182295</td>\n",
       "      <td>3.990066</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.176726</td>\n",
       "      <td>4.261467</td>\n",
       "      <td>0.808081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_score\n",
       "0  28.369689    4.388958    0.890000\n",
       "1  27.738514    3.828265    0.890000\n",
       "2  26.612033    4.037036    0.820000\n",
       "3  27.182295    3.990066    0.890000\n",
       "4  24.176726    4.261467    0.808081"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mean of the test_score with OneVsOne: 0.8596161616161616\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.580022</td>\n",
       "      <td>3.786295</td>\n",
       "      <td>0.85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.182423</td>\n",
       "      <td>3.762829</td>\n",
       "      <td>0.87000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.759525</td>\n",
       "      <td>3.761971</td>\n",
       "      <td>0.86000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.129227</td>\n",
       "      <td>3.783057</td>\n",
       "      <td>0.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.500609</td>\n",
       "      <td>3.776826</td>\n",
       "      <td>0.79798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_score\n",
       "0  26.580022    3.786295     0.85000\n",
       "1  25.182423    3.762829     0.87000\n",
       "2  24.759525    3.761971     0.86000\n",
       "3  25.129227    3.783057     0.90000\n",
       "4  23.500609    3.776826     0.79798"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mean of the test_score with OneVsAll: 0.8555959595959596\n"
     ]
    }
   ],
   "source": [
    "model_Rf = RandomForest\n",
    "\n",
    "onevone_transform = OneVsOne(model_Rf)\n",
    "estimator_ovo = Pipeline([(\"Imputer\", median_imputer),(\"Transformer\", onevone_transform)])\n",
    "\n",
    "val_ovo = cross_validate(estimator_ovo, dataset, y.ravel(), cv=5)\n",
    "\n",
    "display(pd.DataFrame(val_ovo))\n",
    "mean_val_ovo = val_ovo[\"test_score\"].mean()\n",
    "print(\"This is the mean of the test_score with OneVsOne:\", mean_val_ovo)\n",
    "\n",
    "# Now the same with OneVsAll\n",
    "\n",
    "onevall_transform = OneVsAll(model_Rf)\n",
    "estimator_ova = Pipeline([(\"Imputer\", median_imputer),(\"Transformer\", onevone_transform)])\n",
    "\n",
    "val_ova = cross_validate(estimator_ova, dataset, y.ravel(), cv=5)\n",
    "\n",
    "display(pd.DataFrame(val_ova))\n",
    "mean_val_ova = val_ova[\"test_score\"].mean()\n",
    "print(\"This is the mean of the test_score with OneVsAll:\", mean_val_ova)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For curiosity's sake we also try XGBoost, which is currently the leading machine learning algorithm in terms of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.194874</td>\n",
       "      <td>4.386270</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.228040</td>\n",
       "      <td>4.512076</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.313812</td>\n",
       "      <td>4.657213</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.476341</td>\n",
       "      <td>5.541183</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.908222</td>\n",
       "      <td>5.804480</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  2.194874    4.386270    0.870000\n",
       "1  2.228040    4.512076    0.880000\n",
       "2  2.313812    4.657213    0.880000\n",
       "3  2.476341    5.541183    0.880000\n",
       "4  2.908222    5.804480    0.818182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mean of the test_score with OneVsOne: 0.8656363636363636\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.498078</td>\n",
       "      <td>4.866985</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.400582</td>\n",
       "      <td>4.686468</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.361686</td>\n",
       "      <td>4.792182</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.364677</td>\n",
       "      <td>4.731938</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.375649</td>\n",
       "      <td>4.847079</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  2.498078    4.866985    0.870000\n",
       "1  2.400582    4.686468    0.880000\n",
       "2  2.361686    4.792182    0.880000\n",
       "3  2.364677    4.731938    0.880000\n",
       "4  2.375649    4.847079    0.818182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mean of the test_score with OneVsAll: 0.8656363636363636\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgb.XGBClassifier\n",
    "\n",
    "onevone_transform = OneVsOne(model_xgb)\n",
    "estimator_ovo = Pipeline([(\"Imputer\", median_imputer),(\"Transformer\", onevone_transform)])\n",
    "\n",
    "val_ovo = cross_validate(estimator_ovo, dataset, y.ravel(), cv=5)\n",
    "\n",
    "display(pd.DataFrame(val_ovo))\n",
    "mean_val_ovo = val_ovo[\"test_score\"].mean()\n",
    "print(\"This is the mean of the test_score with OneVsOne:\", mean_val_ovo)\n",
    "\n",
    "# Now the same with OneVsAll\n",
    "\n",
    "onevall_transform = OneVsAll(model_xgb)\n",
    "estimator_ova = Pipeline([(\"Imputer\", median_imputer),(\"Transformer\", onevone_transform)])\n",
    "\n",
    "val_ova = cross_validate(estimator_ova, dataset, y.ravel(), cv=5)\n",
    "\n",
    "display(pd.DataFrame(val_ova))\n",
    "mean_val_ova = val_ova[\"test_score\"].mean()\n",
    "print(\"This is the mean of the test_score with OneVsAll:\", mean_val_ova)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what we have obtained in the previous chapters, we can draw the following conclusions.\n",
    "The best algorithm for the given dataset is the linear kernelized SVM, while slightly below it are tied ANN, Random Forest, and XGBoost. This means that very likely the dataset has been generated linearly with some perturbations, with the SVM capturing the linearity best (as expected) and the others trying to model the random noise, hence overfitting in the end.\n",
    "Moreover the difference between OneVsOne and OneVsAll is not great, indeed with some algorithms the former works more efficiently, while with others the converse is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** In this context hyperparameter optimization would produce no benefit. Multiple models with very different characteristics and properties all hit a performance wall around 0.87, meaning that it is extremely unlikely that any tinkering would improve the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
